{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mvcnn_10.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "C2Qg-3snJsa3",
        "nnFSDhosJ-TJ",
        "mVhK7Uz-KUt5",
        "kfZlGitvKj7C",
        "g0W2OfxbMNIo",
        "EUWDtWpdgBNK"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Qg-3snJsa3"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO3kiz5IJkXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0a3a29-d3bf-443e-910a-395f0c69fecb"
      },
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import torch.utils.data\n",
        "import os\n",
        "import math\n",
        "from skimage import io, transform\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision as vision\n",
        "from torchvision import transforms, datasets\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "!pip install tensorboardX\n",
        "from tensorboardX import SummaryWriter\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 92 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 122 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DybSGcj0JzIF"
      },
      "source": [
        "# data loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnFSDhosJ-TJ"
      },
      "source": [
        "## single"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB_i7rUTJ2B5"
      },
      "source": [
        "class SingleImgDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, scale_aug=False, rot_aug=False, test_mode=False, \\\n",
        "                 num_models=0, num_views=20):\n",
        "        self.classnames=['bed','bench','cup','chair','dresser','flower_pot','sofa','stool','table','xbox']\n",
        "        self.root_dir = root_dir\n",
        "        self.scale_aug = scale_aug\n",
        "        self.rot_aug = rot_aug\n",
        "        self.test_mode = test_mode\n",
        "\n",
        "        set_ = root_dir.split('/')[-2]\n",
        "        parent_dir = root_dir.rsplit('/',3)[0]\n",
        "        self.filepaths = []\n",
        "        print(parent_dir)\n",
        "        print(set_)\n",
        "        for i in range(len(self.classnames)):\n",
        "            \n",
        "            all_files = sorted(glob.glob(parent_dir+'/'+self.classnames[i]+'/'+set_+'/*/*.png'))\n",
        "            if num_models == 0:\n",
        "                # Use the whole dataset\n",
        "                self.filepaths.extend(all_files)\n",
        "            else:\n",
        "                self.filepaths.extend(all_files[:min(num_models,len(all_files))])\n",
        "\n",
        "        image_size = (224,224)\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(), \n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.filepaths[idx]\n",
        "        class_name = path.split('/')[-4]\n",
        "        \n",
        "        class_id = self.classnames.index(class_name)\n",
        "\n",
        "        # Use PIL instead\n",
        "        im = Image.open(self.filepaths[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "\n",
        "        return (class_id, im, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVhK7Uz-KUt5"
      },
      "source": [
        "## multi-views"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rndp0McNKaUC"
      },
      "source": [
        "class MultiviewImgDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, scale_aug=False, rot_aug=False, test_mode=False, \\\n",
        "                 num_models=0, num_views=20, shuffle=True):\n",
        "        self.classnames=['bed','bench','cup','chair','dresser','flower_pot','sofa','stool','table','xbox']\n",
        "        self.root_dir = root_dir\n",
        "        self.scale_aug = scale_aug\n",
        "        self.rot_aug = rot_aug\n",
        "        self.test_mode = test_mode\n",
        "        self.num_views = num_views\n",
        "\n",
        "        set_ = root_dir.split('/')[-2]\n",
        "        parent_dir = root_dir.rsplit('/',3)[0]\n",
        "        self.filepaths = []\n",
        "        for i in range(len(self.classnames)):\n",
        "            all_files = sorted(glob.glob(parent_dir+'/'+self.classnames[i]+'/'+set_+'/*/*.png'))\n",
        "            ## Select subset for different number of views\n",
        "            stride = int(20/self.num_views) # 20 6 4 3 2 1\n",
        "            all_files = all_files[::stride]\n",
        "\n",
        "            if num_models == 0:\n",
        "                # Use the whole dataset\n",
        "                self.filepaths.extend(all_files)\n",
        "            else:\n",
        "                self.filepaths.extend(all_files[:min(num_models,len(all_files))])\n",
        "\n",
        "        if shuffle==True:\n",
        "            # permute\n",
        "            rand_idx = np.random.permutation(int(len(self.filepaths)/num_views))\n",
        "            filepaths_new = []\n",
        "            for i in range(len(rand_idx)):\n",
        "                filepaths_new.extend(self.filepaths[rand_idx[i]*num_views:(rand_idx[i]+1)*num_views])\n",
        "            self.filepaths = filepaths_new\n",
        "\n",
        "        image_size = (224,224)\n",
        "        if self.test_mode:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize(image_size),                        \n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "            ])    \n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.Resize(image_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.filepaths)/self.num_views)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.filepaths[idx*self.num_views]\n",
        "        class_name = path.split('/')[-4]\n",
        "        class_id = self.classnames.index(class_name)\n",
        "        # Use PIL instead\n",
        "        imgs = []\n",
        "        for i in range(self.num_views):\n",
        "            im = Image.open(self.filepaths[idx*self.num_views+i]).convert('RGB')\n",
        "            if self.transform:\n",
        "                im = self.transform(im)\n",
        "            imgs.append(im)\n",
        "\n",
        "        return (class_id, torch.stack(imgs), self.filepaths[idx*self.num_views:(idx+1)*self.num_views])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfZlGitvKj7C"
      },
      "source": [
        "## multi-views-res"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QtZLmcVKyYL"
      },
      "source": [
        "class MultiviewAndResImgDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, dataset_norm, dataset_30, dataset_60, shuffle=True):\n",
        "        self.dataset_norm = dataset_norm\n",
        "        self.dataset_30 = dataset_30\n",
        "        self.dataset_60 = dataset_60\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x_norm = self.dataset_norm[index]\n",
        "        x_30 = self.dataset_30[index]\n",
        "        x_60 = self.dataset_60[index]\n",
        "        return x_norm, x_30, x_60\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset_norm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0W2OfxbMNIo"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Taj2X3ojMQO8"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, name):\n",
        "        super(Model, self).__init__()\n",
        "        self.name = name\n",
        "\n",
        "\n",
        "    def save(self, path, epoch=0):\n",
        "        complete_path = os.path.join(path, self.name)\n",
        "        if not os.path.exists(complete_path):\n",
        "            os.makedirs(complete_path)\n",
        "        torch.save(self.state_dict(), \n",
        "                os.path.join(complete_path, \n",
        "                    \"model-{}.pth\".format(str(epoch).zfill(5))))\n",
        "\n",
        "\n",
        "    def save_results(self, path, data):\n",
        "        raise NotImplementedError(\"Model subclass must implement this method.\")\n",
        "        \n",
        "\n",
        "    def load(self, path, modelfile=None):\n",
        "        complete_path = os.path.join(path, self.name)\n",
        "        if not os.path.exists(complete_path):\n",
        "            raise IOError(\"{} directory does not exist in {}\".format(self.name, path))\n",
        "\n",
        "        if modelfile is None:\n",
        "            model_files = glob.glob(complete_path+\"/*\")\n",
        "            mf = max(model_files)\n",
        "        else:\n",
        "            mf = os.path.join(complete_path, modelfile)\n",
        "\n",
        "        self.load_state_dict(torch.load(mf))\n",
        "\n",
        "import torchvision.models as models\n",
        "class SVCNN(Model):\n",
        "\n",
        "    def __init__(self, name, nclasses=10, pretraining=True):\n",
        "        super(SVCNN, self).__init__(name)\n",
        "\n",
        "        self.classnames=['bed','bench','cup','chair','dresser','flower_pot','sofa','stool','table','xbox']\n",
        "\n",
        "        self.nclasses = nclasses\n",
        "        self.pretraining = pretraining\n",
        "        \n",
        "        self.net_1 = models.alexnet(pretrained=self.pretraining).features\n",
        "        self.net_2 = models.alexnet(pretrained=self.pretraining).classifier   \n",
        "        self.net_2._modules['6'] = nn.Linear(4096,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.net_1(x)\n",
        "        return self.net_2(y.view(y.shape[0],-1))\n",
        "\n",
        "\n",
        "class MVCNN(Model):\n",
        "\n",
        "    def __init__(self, name, model, nclasses=10, num_views=20):\n",
        "        super(MVCNN, self).__init__(name)\n",
        "\n",
        "        self.classnames=['bed','bench','cup','chair','dresser','flower_pot','sofa','stool','table','xbox']\n",
        "\n",
        "        self.nclasses = nclasses\n",
        "        self.num_views = num_views\n",
        "\n",
        "        self.net_1 = model.net_1\n",
        "        self.net_2 = model.net_2\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.net_1(x)\n",
        "        y = y.view((int(x.shape[0]/self.num_views),self.num_views,y.shape[-3],y.shape[-2],y.shape[-1]))#(8,20,512,7,7)\n",
        "        return self.net_2(torch.max(y,1)[0].view(y.shape[0],-1))\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        \"\"\" Returns output of the FC7 \"\"\"\n",
        "        y = self.net_1(x)\n",
        "        y = y.view((int(x.shape[0]/self.num_views),self.num_views,y.shape[-3],y.shape[-2],y.shape[-1]))#(8,20,512,7,7)\n",
        "        y = self.net_2._modules['0'](torch.max(y,1)[0].view(y.shape[0],-1))\n",
        "        y = self.net_2._modules['1'](y)\n",
        "        y = self.net_2._modules['2'](y)\n",
        "        y = self.net_2._modules['3'](y)\n",
        "        y = self.net_2._modules['4'](y)\n",
        "        # y = self.net_2._modules['5'](y)\n",
        "        return self.net_2._modules['5'](y)\n",
        "\n",
        "class MVCNN_RES(Model):\n",
        "    def __init__(self, name, model_norm, model_30, model_60, nclasses=10, num_views=20):\n",
        "        super(MVCNN_RES, self).__init__(name)\n",
        "\n",
        "        self.classnames=['bed','bench','cup','chair','dresser','flower_pot','sofa','stool','table','xbox']\n",
        "\n",
        "        self.nclasses = nclasses\n",
        "        self.num_views = num_views\n",
        "\n",
        "        self.net_1_norm = model_norm.net_1\n",
        "        self.net_2 = model_norm.net_2\n",
        "\n",
        "        self.net_1_30 = model_30.net_1\n",
        "       \n",
        "        self.net_1_60 = model_60.net_1\n",
        "        \n",
        "\n",
        "    def forward(self, x_norm, x_30, x_60):\n",
        "        y1 = self.net_1_norm(x_norm)\n",
        "        y2 = self.net_1_30(x_30)\n",
        "        y3 = self.net_1_60(x_60)\n",
        "        \n",
        "        y1 = y1.view((int(x_norm.shape[0]/self.num_views),self.num_views,y1.shape[-3],y1.shape[-2],y1.shape[-1]))#(8,20,512,7,7)\n",
        "        print(y1.shape)\n",
        "        y2 = y2.view((int(x_norm.shape[0]/self.num_views),self.num_views,y2.shape[-3],y2.shape[-2],y2.shape[-1]))#(8,20,512,7,7)\n",
        "        y3 = y3.view((int(x_norm.shape[0]/self.num_views),self.num_views,y3.shape[-3],y3.shape[-2],y3.shape[-1]))#(8,20,512,7,7)\n",
        "        y = torch.cat([y1, y2, y3],dim=1)\n",
        "\n",
        "        return self.net_2(torch.max(y,1)[0].view(y.shape[0],-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dv9oONtQc5n"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUWDtWpdgBNK"
      },
      "source": [
        "## train for MVCNN/SVCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um1m33p5QfPb"
      },
      "source": [
        "class ModelNetTrainer(object):\n",
        "\n",
        "    def __init__(self, model, train_loader, val_loader, optimizer, loss_fn, \\\n",
        "                 model_name, log_dir, num_views=20):\n",
        "\n",
        "        self.optimizer = optimizer\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model_name = model_name\n",
        "        self.log_dir = log_dir\n",
        "        self.num_views = num_views\n",
        "\n",
        "        self.model.cuda()\n",
        "        if self.log_dir is not None:\n",
        "            self.writer = SummaryWriter(log_dir)\n",
        "\n",
        "\n",
        "    def train(self, n_epochs):\n",
        "\n",
        "        best_acc = 0\n",
        "        i_acc = 0\n",
        "        self.model.train()\n",
        "        for epoch in range(n_epochs):\n",
        "            # permute data for mvcnn\n",
        "            rand_idx = np.random.permutation(int(len(self.train_loader.dataset.filepaths)/self.num_views))\n",
        "            filepaths_new = []\n",
        "            for i in range(len(rand_idx)):\n",
        "                filepaths_new.extend(self.train_loader.dataset.filepaths[rand_idx[i]*self.num_views:(rand_idx[i]+1)*self.num_views])\n",
        "            self.train_loader.dataset.filepaths = filepaths_new\n",
        "\n",
        "            # plot learning rate\n",
        "            lr = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
        "            self.writer.add_scalar('params/lr', lr, epoch)\n",
        "\n",
        "            # train one epoch\n",
        "            out_data = None\n",
        "            in_data = None\n",
        "            for i, data in enumerate(self.train_loader):\n",
        "\n",
        "                if self.model_name == 'mvcnn':\n",
        "                    N,V,C,H,W = data[1].size()\n",
        "                    in_data = Variable(data[1]).view(-1,C,H,W).cuda()\n",
        "                else:\n",
        "                    in_data = Variable(data[1].cuda())\n",
        "                target = Variable(data[0]).cuda().long()\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                out_data = self.model(in_data)\n",
        "\n",
        "                loss = self.loss_fn(out_data, target)\n",
        "                \n",
        "                self.writer.add_scalar('train/train_loss', loss, i_acc+i+1)\n",
        "\n",
        "                pred = torch.max(out_data, 1)[1]\n",
        "                results = pred == target\n",
        "                correct_points = torch.sum(results.long())\n",
        "\n",
        "                acc = correct_points.float()/results.size()[0]\n",
        "                self.writer.add_scalar('train/train_overall_acc', acc, i_acc+i+1)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                \n",
        "                log_str = 'epoch %d, step %d: train_loss %.3f; train_acc %.3f' % (epoch+1, i+1, loss, acc)\n",
        "                if (i+1)%1==0:\n",
        "                    print(log_str)\n",
        "            i_acc += i\n",
        "\n",
        "            # evaluation\n",
        "            if (epoch+1)%1==0:\n",
        "                with torch.no_grad():\n",
        "                    loss, val_overall_acc, val_mean_class_acc = self.update_validation_accuracy(epoch)\n",
        "                self.writer.add_scalar('val/val_mean_class_acc', val_mean_class_acc, epoch+1)\n",
        "                self.writer.add_scalar('val/val_overall_acc', val_overall_acc, epoch+1)\n",
        "                self.writer.add_scalar('val/val_loss', loss, epoch+1)\n",
        "\n",
        "            # save best model\n",
        "            if val_overall_acc > best_acc:\n",
        "                best_acc = val_overall_acc\n",
        "                self.model.save(self.log_dir, epoch)\n",
        " \n",
        "            # adjust learning rate manually\n",
        "            if epoch > 0 and (epoch+1) % 10 == 0:\n",
        "                for param_group in self.optimizer.param_groups:\n",
        "                    param_group['lr'] = param_group['lr']*0.5\n",
        "\n",
        "        # export scalar data to JSON for external processing\n",
        "        self.writer.export_scalars_to_json(self.log_dir+\"/all_scalars.json\")\n",
        "        self.writer.close()\n",
        "\n",
        "    def update_validation_accuracy(self, epoch):\n",
        "        all_correct_points = 0\n",
        "        all_points = 0\n",
        "\n",
        "        # in_data = None\n",
        "        # out_data = None\n",
        "        # target = None\n",
        "\n",
        "        wrong_class = np.zeros(10)\n",
        "        samples_class = np.zeros(10)\n",
        "        all_loss = 0\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        avgpool = nn.AvgPool1d(1, 1)\n",
        "\n",
        "        total_time = 0.0\n",
        "        total_print_time = 0.0\n",
        "        all_target = []\n",
        "        all_pred = []\n",
        "\n",
        "        for _, data in enumerate(self.val_loader, 0):\n",
        "\n",
        "            if self.model_name == 'mvcnn':\n",
        "                N,V,C,H,W = data[1].size()\n",
        "                in_data = Variable(data[1]).view(-1,C,H,W).cuda()\n",
        "            else:#'svcnn'\n",
        "                in_data = Variable(data[1]).cuda()\n",
        "            target = Variable(data[0]).cuda()\n",
        "\n",
        "            out_data = self.model(in_data)\n",
        "            pred = torch.max(out_data, 1)[1]\n",
        "            all_loss += self.loss_fn(out_data, target).cpu().data.numpy()\n",
        "            results = pred == target\n",
        "\n",
        "            for i in range(results.size()[0]):\n",
        "                if not bool(results[i].cpu().data.numpy()):\n",
        "                    wrong_class[target.cpu().data.numpy().astype('int')[i]] += 1\n",
        "                samples_class[target.cpu().data.numpy().astype('int')[i]] += 1\n",
        "            correct_points = torch.sum(results.long())\n",
        "\n",
        "            all_correct_points += correct_points\n",
        "            all_points += results.size()[0]\n",
        "\n",
        "        print ('Total # of test models: ', all_points)\n",
        "        val_mean_class_acc = np.mean((samples_class-wrong_class)/samples_class)\n",
        "        acc = all_correct_points.float() / all_points\n",
        "        val_overall_acc = acc.cpu().data.numpy()\n",
        "        loss = all_loss / len(self.val_loader)\n",
        "\n",
        "        print ('val mean class acc. : ', val_mean_class_acc)\n",
        "        print ('val overall acc. : ', val_overall_acc)\n",
        "        print ('val loss : ', loss)\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        return loss, val_overall_acc, val_mean_class_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aL0XKJ_gJq7"
      },
      "source": [
        "## train for multi-input MVCNN-RES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUNNH8mCf6Ka"
      },
      "source": [
        "class ModelMutiNetTrainer(object):\n",
        "\n",
        "    def __init__(self, model, train_loader, val_loader, optimizer, loss_fn, \\\n",
        "                 model_name, log_dir, num_views=20, num_res=3):\n",
        "        # input trained mvcnn for 3 res-data separately  \n",
        "        self.model = model\n",
        "\n",
        "        # load data\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "        # setting for trainer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        # logging\n",
        "        self.model_name = model_name\n",
        "        self.log_dir = log_dir\n",
        "\n",
        "        # detail for dataset\n",
        "        self.num_views = num_views\n",
        "        self.num_res = num_res\n",
        "\n",
        "        # using GPU \n",
        "        self.device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(device)\n",
        "        if self.log_dir is not None:\n",
        "            self.writer = SummaryWriter(log_dir)\n",
        "\n",
        "\n",
        "    def train(self, n_epochs):\n",
        "\n",
        "        best_acc = 0\n",
        "        i_acc = 0\n",
        "        for epoch in range(n_epochs):\n",
        "\n",
        "            # permute data for mvcnn\n",
        "            rand_idx = np.random.permutation(int(len(self.train_loader.dataset.dataset_norm.filepaths)/self.num_views))\n",
        "            filepaths_new_norm = []\n",
        "            filepaths_new_30 = []\n",
        "            filepaths_new_60 = []\n",
        "            for i in range(len(rand_idx)):\n",
        "                filepaths_new_norm.extend(self.train_loader.dataset.dataset_norm.filepaths[rand_idx[i]*self.num_views:(rand_idx[i]+1)*self.num_views])\n",
        "                filepaths_new_30.extend(self.train_loader.dataset.dataset_30.filepaths[rand_idx[i]*self.num_views:(rand_idx[i]+1)*self.num_views])\n",
        "                filepaths_new_60.extend(self.train_loader.dataset.dataset_60.filepaths[rand_idx[i]*self.num_views:(rand_idx[i]+1)*self.num_views])\n",
        "            self.train_loader.dataset.dataset_norm.filepaths = filepaths_new_norm\n",
        "            self.train_loader.dataset.dataset_30.filepaths = filepaths_new_30\n",
        "            self.train_loader.dataset.dataset_60.filepaths = filepaths_new_60\n",
        "\n",
        "            # plot learning rate\n",
        "            lr = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
        "            self.writer.add_scalar('params/lr', lr, epoch)\n",
        "\n",
        "            # train one epoch\n",
        "            out_data = None\n",
        "            in_data = None\n",
        "            for i, data in enumerate(self.train_loader):\n",
        "\n",
        "                N,V,C,H,W = data[0][1].size()\n",
        "                in_data_norm = Variable(data[0][1]).view(-1,C,H,W).to(device)\n",
        "                in_data_30 = Variable(data[1][1]).view(-1,C,H,W).to(device)\n",
        "                in_data_60 = Variable(data[2][1]).view(-1,C,H,W).to(device)\n",
        "\n",
        "                target = Variable(data[0][0]).to(device).long()\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                out_data = self.model(in_data_norm, in_data_30, in_data_60)\n",
        "\n",
        "                loss = self.loss_fn(out_data, target)\n",
        "                \n",
        "                self.writer.add_scalar('train/train_loss', loss, i_acc+i+1)\n",
        "\n",
        "                pred = torch.max(out_data, 1)[1]\n",
        "                results = pred == target\n",
        "                correct_points = torch.sum(results.long())\n",
        "\n",
        "                acc = correct_points.float()/results.size()[0]\n",
        "                self.writer.add_scalar('train/train_overall_acc', acc, i_acc+i+1)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                \n",
        "                log_str = 'epoch %d, step %d: train_loss %.3f; train_acc %.3f' % (epoch+1, i+1, loss, acc)\n",
        "                if (i+1)%1==0:\n",
        "                    print(log_str)\n",
        "            i_acc += i\n",
        "\n",
        "            # evaluation\n",
        "            if (epoch+1)%1==0:\n",
        "                with torch.no_grad():\n",
        "                    loss, val_overall_acc, val_mean_class_acc = self.update_validation_accuracy(epoch)\n",
        "                self.writer.add_scalar('val/val_mean_class_acc', val_mean_class_acc, epoch+1)\n",
        "                self.writer.add_scalar('val/val_overall_acc', val_overall_acc, epoch+1)\n",
        "                self.writer.add_scalar('val/val_loss', loss, epoch+1)\n",
        "\n",
        "            # save best model\n",
        "            if val_overall_acc > best_acc:\n",
        "                best_acc = val_overall_acc\n",
        "                self.model.save(self.log_dir, epoch)\n",
        " \n",
        "            # adjust learning rate manually\n",
        "            if epoch > 0 and (epoch+1) % 10 == 0:\n",
        "                for param_group in self.optimizer.param_groups:\n",
        "                    param_group['lr'] = param_group['lr']*0.5\n",
        "\n",
        "        # export scalar data to JSON for external processing\n",
        "        self.writer.export_scalars_to_json(self.log_dir+\"/all_scalars.json\")\n",
        "        self.writer.close()\n",
        "\n",
        "    def update_validation_accuracy(self, epoch):\n",
        "        all_correct_points = 0\n",
        "        all_points = 0\n",
        "\n",
        "        # in_data = None\n",
        "        # out_data = None\n",
        "        # target = None\n",
        "\n",
        "        wrong_class = np.zeros(10)\n",
        "        samples_class = np.zeros(10)\n",
        "        all_loss = 0\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        avgpool = nn.AvgPool1d(1, 1)\n",
        "\n",
        "        total_time = 0.0\n",
        "        total_print_time = 0.0\n",
        "        all_target = []\n",
        "        all_pred = []\n",
        "\n",
        "        for _, data in enumerate(self.val_loader, 0):\n",
        "            N,V,C,H,W = data[0][1].size()\n",
        "            in_data_norm = Variable(data[0][1]).view(-1,C,H,W).to(device)\n",
        "            in_data_30 = Variable(data[1][1]).view(-1,C,H,W).to(device)\n",
        "            in_data_60 = Variable(data[2][1]).view(-1,C,H,W).to(device)\n",
        "\n",
        "            target = Variable(data[0][0]).to(device)\n",
        "\n",
        "\n",
        "            out_data = self.model(in_data_norm, in_data_30, in_data_60)\n",
        "\n",
        "            pred = torch.max(out_data, 1)[1]\n",
        "            all_loss += self.loss_fn(out_data, target).cpu().data.numpy()\n",
        "            results = pred == target\n",
        "\n",
        "            for i in range(results.size()[0]):\n",
        "                if not bool(results[i].cpu().data.numpy()):\n",
        "                    wrong_class[target.cpu().data.numpy().astype('int')[i]] += 1\n",
        "                samples_class[target.cpu().data.numpy().astype('int')[i]] += 1\n",
        "            correct_points = torch.sum(results.long())\n",
        "\n",
        "            all_correct_points += correct_points\n",
        "            all_points += results.size()[0]\n",
        "\n",
        "        print ('Total # of test models: ', all_points)\n",
        "        val_mean_class_acc = np.mean((samples_class-wrong_class)/samples_class)\n",
        "        acc = all_correct_points.float() / all_points\n",
        "        val_overall_acc = acc.cpu().data.numpy()\n",
        "        loss = all_loss / len(self.val_loader)\n",
        "\n",
        "        print ('val mean class acc. : ', val_mean_class_acc)\n",
        "        print ('val overall acc. : ', val_overall_acc)\n",
        "        print ('val loss : ', loss)\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        return loss, val_overall_acc, val_mean_class_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAeIUiT1tKZ3"
      },
      "source": [
        "## training for MVCNN-RES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m5E2ZZDtQdG"
      },
      "source": [
        "import torch.optim as optim\n",
        "model = MVCNN_RES('MVCNN-RES', model_2_norm, model_2_30, model_2_60)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0, betas=(0.9, 0.999))\n",
        "trainer = ModelMutiNetTrainer(model, train_loader_multi, test_loader_multi, optimizer, nn.CrossEntropyLoss(), 'MVCNN-RES', 'MVCNN-RES', num_views=20)\n",
        "trainer.train(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSNAqa0EcxBV"
      },
      "source": [
        "# CNN-feather"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhzmFg8A2XIb"
      },
      "source": [
        "## test for tensor to pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "UC8oSqxG6LSj",
        "outputId": "9b2a87ce-bade-4394-8caa-c660069115e3"
      },
      "source": [
        "import torch\n",
        "import pandas as  pd\n",
        "\n",
        "x1 = torch.rand(4,4)\n",
        "x2 = torch.rand(4,4)\n",
        "y = torch.rand(8,1)\n",
        "px = pd.DataFrame(x1.numpy())\n",
        "px = px.append(pd.DataFrame(x2.numpy()), ignore_index=True)\n",
        "px['label'] = y.numpy()\n",
        "px"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.261833</td>\n",
              "      <td>0.111066</td>\n",
              "      <td>0.692498</td>\n",
              "      <td>0.743136</td>\n",
              "      <td>0.375229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.100112</td>\n",
              "      <td>0.144430</td>\n",
              "      <td>0.947567</td>\n",
              "      <td>0.316236</td>\n",
              "      <td>0.376510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.579914</td>\n",
              "      <td>0.612485</td>\n",
              "      <td>0.760884</td>\n",
              "      <td>0.346794</td>\n",
              "      <td>0.814628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.344728</td>\n",
              "      <td>0.113983</td>\n",
              "      <td>0.637992</td>\n",
              "      <td>0.417706</td>\n",
              "      <td>0.293498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.512333</td>\n",
              "      <td>0.367342</td>\n",
              "      <td>0.956675</td>\n",
              "      <td>0.285753</td>\n",
              "      <td>0.314751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.522563</td>\n",
              "      <td>0.021251</td>\n",
              "      <td>0.202982</td>\n",
              "      <td>0.395416</td>\n",
              "      <td>0.017155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.800201</td>\n",
              "      <td>0.134736</td>\n",
              "      <td>0.866983</td>\n",
              "      <td>0.012809</td>\n",
              "      <td>0.190610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.331038</td>\n",
              "      <td>0.346326</td>\n",
              "      <td>0.228763</td>\n",
              "      <td>0.319438</td>\n",
              "      <td>0.585658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3     label\n",
              "0  0.261833  0.111066  0.692498  0.743136  0.375229\n",
              "1  0.100112  0.144430  0.947567  0.316236  0.376510\n",
              "2  0.579914  0.612485  0.760884  0.346794  0.814628\n",
              "3  0.344728  0.113983  0.637992  0.417706  0.293498\n",
              "4  0.512333  0.367342  0.956675  0.285753  0.314751\n",
              "5  0.522563  0.021251  0.202982  0.395416  0.017155\n",
              "6  0.800201  0.134736  0.866983  0.012809  0.190610\n",
              "7  0.331038  0.346326  0.228763  0.319438  0.585658"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ1DGS0Y2d_F"
      },
      "source": [
        "## get_feather(name, train_dataset, train_loader, model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-viGJfuaDte"
      },
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import pandas as  pd\n",
        "def get_feather(name, train_dataset, train_loader, model):\n",
        "\n",
        "  model=model.to(device)\n",
        "  nb_features = 4096\n",
        "  lens = int(len(train_dataset.filepaths)/8/20)\n",
        "  for i, data in enumerate(train_loader):\n",
        "      N,V,C,H,W = data[1].size()\n",
        "      in_data = Variable(data[1]).view(-1,C,H,W).to(device)\n",
        "      out_data = model.extract_features(in_data).data\n",
        "      feather = out_data.cpu().detach().numpy()\n",
        "      target = data[0].numpy()\n",
        "      if i == 0:\n",
        "        p_feather = pd.DataFrame(feather)\n",
        "        labels = pd.DataFrame(target)\n",
        "      else:\n",
        "        p_feather = p_feather.append(pd.DataFrame(feather), ignore_index=True)\n",
        "        labels = labels.append(pd.DataFrame(target), ignore_index=True)\n",
        "      if i % 10 == 0 or i == lens:\n",
        "        print(i)\n",
        "        p_feather.to_csv(name + 'CNN-feather.csv')\n",
        "        labels.to_csv(name + 'CNN-feather-labels.csv')\n",
        "\n",
        "  print('CNN features obtained and saved.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCN0Jwfoc6OQ"
      },
      "source": [
        "# connect google "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWrmox7KcTDl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnKyb7mzdH2H"
      },
      "source": [
        "# load trained mvcnn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABC4TlbvZkqh",
        "outputId": "c1ab78d7-29d1-49ba-cc0b-1fa5e864e85e"
      },
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model_1 = SVCNN(\"svcnn\")\n",
        "model_2_norm = MVCNN('MVCNN',model=model_1).to(device)\n",
        "model_2_30 = MVCNN('MVCNN',model=model_1)\n",
        "model_2_60 = MVCNN('MVCNN',model=model_1)\n",
        "\n",
        "model_weight_path_norm = torch.load('/content/drive/MyDrive/mvcnn/running_cache5_stage_2/running_cache5/model-00002.pth', map_location=device)\n",
        "model_2_norm.load_state_dict(model_weight_path_norm)\n",
        "\n",
        "model_weight_path_30 = torch.load('/content/drive/MyDrive/mvcnn/running_cache30_stage_2/running_cache30/model-00001.pth')\n",
        "model_2_30.load_state_dict(model_weight_path_30)\n",
        "\n",
        "model_weight_path_60 = torch.load('/content/drive/MyDrive/mvcnn/running_cache60_stage_2/running_cache60/model-00000.pth', map_location=device)\n",
        "model_2_60.load_state_dict(model_weight_path_60)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb2BBaU5dRMp"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfGAoc8v3Gui"
      },
      "source": [
        "## train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdO_tZqoazKW",
        "outputId": "e2556478-befc-4fad-9df5-ad4c77d01fc5"
      },
      "source": [
        "train_path_norm = '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/*/train/*'\n",
        "train_dataset_norm = MultiviewImgDataset(train_path_norm, scale_aug=False, rot_aug=False, shuffle=False, num_models=0, num_views=20)\n",
        "train_loader_norm = torch.utils.data.DataLoader(train_dataset_norm, batch_size=8, shuffle=False, num_workers=0)\n",
        "print('num_train_files(norm): '+str(len(train_dataset_norm.filepaths)))\n",
        "\n",
        "train_path_30 = '/content/drive/MyDrive/data/ModelNet4_voxel_20views_30/*/train/*'\n",
        "train_dataset_30 = MultiviewImgDataset(train_path_30, scale_aug=False, rot_aug=False, shuffle=False, num_models=0, num_views=20)\n",
        "train_loader_30 = torch.utils.data.DataLoader(train_dataset_30, batch_size=8, shuffle=False, num_workers=0)\n",
        "print('num_train_files(30 res): '+str(len(train_dataset_30.filepaths)))\n",
        "\n",
        "train_path_60 = '/content/drive/MyDrive/data/ModelNet4_voxel_20views_60/*/train/*'\n",
        "train_dataset_60 = MultiviewImgDataset(train_path_60, scale_aug=False, rot_aug=False, shuffle=False, num_models=0, num_views=20)\n",
        "train_loader_60 = torch.utils.data.DataLoader(train_dataset_60, batch_size=8, shuffle=False, num_workers=0)\n",
        "print('num_train_files(60 res): '+str(len(train_dataset_60.filepaths)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_train_files(30 res): 31840\n",
            "num_train_files(60 res): 31840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfqT6VjX3IyS"
      },
      "source": [
        "## test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eed8grft3K25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b10060-f508-461a-b366-eaa5eff33ce3"
      },
      "source": [
        "test_path_norm = '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/*/test/*'\n",
        "test_dataset_norm = MultiviewImgDataset(test_path_norm, scale_aug=False, rot_aug=False, shuffle=False, num_models=0, num_views=20)\n",
        "test_loader_norm = torch.utils.data.DataLoader(test_dataset_norm, batch_size=8, shuffle=False, num_workers=0)\n",
        "print('num_test_files(norm): '+str(len(test_dataset_norm.filepaths)))\n",
        "\n",
        "test_path_30 = '/content/drive/MyDrive/data/ModelNet4_voxel_20views_30/*/test/*'\n",
        "test_dataset_30 = MultiviewImgDataset(test_path_30, scale_aug=False, rot_aug=False, shuffle=False, num_models=0, num_views=20)\n",
        "test_loader_30 = torch.utils.data.DataLoader(test_dataset_30, batch_size=8, shuffle=False, num_workers=0)\n",
        "print('num_test_files(30 res): '+str(len(test_dataset_30.filepaths)))\n",
        "\n",
        "test_path_60 = '/content/drive/MyDrive/data/ModelNet4_voxel_20views_60/*/test/*'\n",
        "test_dataset_60 = MultiviewImgDataset(test_path_60, scale_aug=False, rot_aug=False, shuffle=False, num_models=0, num_views=20)\n",
        "test_loader_60 = torch.utils.data.DataLoader(test_dataset_60, batch_size=8, shuffle=False, num_workers=0)\n",
        "print('num_test_files(60 res): '+str(len(test_dataset_60.filepaths)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_test_files(30 res): 4460\n",
            "num_test_files(60 res): 4460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2SeILuu7ZS9"
      },
      "source": [
        "# get CNN feather"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcd5K9_77cvK",
        "outputId": "3d2b76a4-c36a-475a-b5f3-d01da7f18e71"
      },
      "source": [
        "# get cnn feather for norm\n",
        "get_feather('norm', train_dataset_norm, train_loader_norm, model_2_norm)\n",
        "\n",
        "# get cnn feather for 30\n",
        "get_feather('30', train_dataset_30, train_loader_30, model_2_30)\n",
        "\n",
        "# get cnn feather for 60\n",
        "get_feather('60', train_dataset_60, train_loader_60, model_2_60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "CNN features obtained and saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbpLCC-oDFBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33689e0c-9cb7-4592-bae0-de12bd43955b"
      },
      "source": [
        "# get cnn feather for norm\n",
        "get_feather('norm-test', test_dataset_norm, test_loader_norm, model_2_norm)\n",
        "\n",
        "# get cnn feather for 60\n",
        "get_feather('60-test', test_dataset_60, test_loader_60, model_2_60)\n",
        "\n",
        "# get cnn feather for 30\n",
        "get_feather('30-test', test_dataset_30, test_loader_30, model_2_30)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "27\n",
            "CNN features obtained and saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlNWfvvl5cqa"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4VtPsbW5gaP"
      },
      "source": [
        "## test for dataloader（loading order）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV8ysxbfyLm5",
        "outputId": "bde0cf2c-13df-4153-d530-4b9a0557333f"
      },
      "source": [
        "print(train_dataset_norm.filepaths[0:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_1.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_10.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_11.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_12.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_13.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_14.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_15.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_16.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_17.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_18.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_19.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_2.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_20.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_3.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_4.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_5.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_6.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_7.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_8.png', '/content/drive/MyDrive/data/ModelNet4_voxel_20views_norm/bed/train/bed_0001.off/bed_0001_9.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89pMoMb455oN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8f4b9AnplGc"
      },
      "source": [
        "train_dataset_multi = MultiviewAndResImgDataset(train_dataset_norm, train_dataset_30, train_dataset_60)\n",
        "train_loader_multi = torch.utils.data.DataLoader(train_dataset_multi, batch_size=8, shuffle=False, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWeaiutUSZ7c"
      },
      "source": [
        "## test for data[0] , data.shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4DZy96CvoLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b80370-fe53-4edf-dccd-0fb492aeae4f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "for i, data in enumerate(train_loader_norm):\n",
        "  if i == 0:\n",
        "    print(data[0])\n",
        "    print(data[0].shape)\n",
        "    p_feather = pd.DataFrame(data[0].numpy())\n",
        "    print(p_feather)\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
            "torch.Size([8])\n",
            "   0\n",
            "0  0\n",
            "1  0\n",
            "2  0\n",
            "3  0\n",
            "4  0\n",
            "5  0\n",
            "6  0\n",
            "7  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mJpKHSAa6Si"
      },
      "source": [
        "get_feather('norm', train_dataset_norm, train_loader_norm, model_2_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCv77Pjy-hT7",
        "outputId": "304b870c-27a8-4caa-8afe-dc13a59e2393"
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    }
  ]
}